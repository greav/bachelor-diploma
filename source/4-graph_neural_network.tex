\section{Глава 4. Графовые нейронные сети}
Графовые нейронные сети (Graph Neural Network - GNN) -- это методы глубокого обучения, основанные на графах. Как правило, они базируются на следующих фундаментальных аспектах: сверточных нейронных сетях (Convolutional Neural Network - CNN) и графовых эмбеддингах. 

Сверточные нейронные сети могут работать только с евклидовыми данными, такими как изображения (двумерная сетка) и эту структуру данных можно рассматривать как граф. Ключевыми принципами сверточных нейронных сетей являются: локальная связь, разделяемые веса и использование многослойности. И эти принципы могут иметь большое значение при решении задач в области графов, поскольку графы являются наиболее типичной локально связной структурой, общие веса снижают вычислительные затраты по сравнению с традиционной теорией спектральных графов, а многослойная структура является ключом к работе с иерархическими структурами, которая отражает особенности различных размеров. 

Главной проблемой для обобщения сверточных нейронных сетей на графы является то, что графы, как правило, в общем случае представляют собой нерегулярную неевклидову структуру данных (число узлов и связей между ними произвольно). Эту проблему и призвана решить графовая нейронная сеть, поскольку CNN, не может должным образом обрабатывать ввод графа, т.к. сверточная нейронная сеть обрабатывает  узлы в определенном порядке. Однако, в графе нет естественного порядка, поэтому, чтобы полностью представить граф, мы должны пройти через все возможные порядки в качестве входных данных модели, которая будет очень избыточна при вычислениях. Для решения этой проблемы, GNN распространяются на каждом узле соответственно, игнорируя порядок ввода узлов. Другими словами, вывод GNN является инвариантным для порядка ввода узлов. 
\textbf{TODO: исправить предыдущий абзац}

Другим важным аспектом является использование графовых эмбеддингов, которые учатся представлять узлы, ребра или подграфы графа в низкоразмерных векторах. Однако, использование методов графовых эмбеддингов имеют два серьезных недостатка. Во-первых, никакие параметры не разделяются между узлами в кодировщике, что приводит к неэффективности вычислений, поскольку это означает, что число параметров растет линейно с количеством узлов. Во-вторых, методы векторного представления, такие как DeepWalk, Node2Vec \textbf{и т.д.}, не имеют возможности обобщения, что означает, что они не могут иметь дело с динамическими графами или обобщаться на новые графы.

Поэтому на основе сверточных нейронных сетях и графовых эмбеддингов были введены графовые нейронные сети коллективно агрегирующие информацию из структуры графов, при это делая это вычислительно более эффективно.

\subsection{4.1. Оригинальная концепция графовой нейронной сети}


\subsection{4.2. GraphSAGE}

Этот подход базируется на сверточных нейронных сетях, обобщая их от обработки простых решеток (сеток изображений) до общих графов. Но как обобщить свертку?

Одним из вариантов обобщения может быть использование матрицы смежности (плюс некоторые признаки узлов) графа и передача его в нейронную сеть. Проблема данного подхода в том, что количество входов линейно по размеру сети (т.е. огромно).

\clearpage